{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_data import read_data\n",
    "\n",
    "\n",
    "def read_data_wrapper(setname, type):\n",
    "    # data = pd.read_hdf(\n",
    "    #     f\"{original_data_path}/{type}{setname}.zarr\"\n",
    "    # )  # fill in your path and file name\n",
    "    data = read_data(setname, type)\n",
    "    return data[[\"case_id\", \"time\", \"x_leader\", \"x_follower\", \"v_leader\", \"v_follower\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>time</th>\n",
       "      <th>x_leader</th>\n",
       "      <th>x_follower</th>\n",
       "      <th>v_leader</th>\n",
       "      <th>v_follower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.428864</td>\n",
       "      <td>2.629775</td>\n",
       "      <td>0.784441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.263154</td>\n",
       "      <td>-9.341833</td>\n",
       "      <td>2.665530</td>\n",
       "      <td>0.810204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.535099</td>\n",
       "      <td>-9.265412</td>\n",
       "      <td>2.776808</td>\n",
       "      <td>0.828016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.828920</td>\n",
       "      <td>-9.107064</td>\n",
       "      <td>2.966034</td>\n",
       "      <td>0.889182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.147062</td>\n",
       "      <td>-8.933068</td>\n",
       "      <td>3.168645</td>\n",
       "      <td>0.979196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.486376</td>\n",
       "      <td>-8.735666</td>\n",
       "      <td>3.348807</td>\n",
       "      <td>1.080297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.844605</td>\n",
       "      <td>-8.579100</td>\n",
       "      <td>3.544290</td>\n",
       "      <td>1.174214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.226670</td>\n",
       "      <td>-8.416525</td>\n",
       "      <td>3.764669</td>\n",
       "      <td>1.322533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.631701</td>\n",
       "      <td>-8.234040</td>\n",
       "      <td>3.978872</td>\n",
       "      <td>1.476311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.056757</td>\n",
       "      <td>-7.929120</td>\n",
       "      <td>4.142739</td>\n",
       "      <td>1.697523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id  time  x_leader  x_follower  v_leader  v_follower\n",
       "0        0   0.0  0.000000   -9.428864  2.629775    0.784441\n",
       "1        0   0.1  0.263154   -9.341833  2.665530    0.810204\n",
       "2        0   0.2  0.535099   -9.265412  2.776808    0.828016\n",
       "3        0   0.3  0.828920   -9.107064  2.966034    0.889182\n",
       "4        0   0.4  1.147062   -8.933068  3.168645    0.979196\n",
       "5        0   0.5  1.486376   -8.735666  3.348807    1.080297\n",
       "6        0   0.6  1.844605   -8.579100  3.544290    1.174214\n",
       "7        0   0.7  2.226670   -8.416525  3.764669    1.322533\n",
       "8        0   0.8  2.631701   -8.234040  3.978872    1.476311\n",
       "9        0   0.9  3.056757   -7.929120  4.142739    1.697523"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_HA = read_data_wrapper(\"HA\", \"train\")\n",
    "data_HA.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26394/26394 [04:00<00:00, 109.91it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_sequences(data, n_steps_in, n_steps_out, step):\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(data) - n_steps_in - n_steps_out + 5, step):\n",
    "        seq_x = data[i : i + n_steps_in]\n",
    "        seq_y = data[i + n_steps_in : i + n_steps_in + n_steps_out]\n",
    "        if seq_x.shape[0] == n_steps_in and seq_y.shape[0] == n_steps_out:\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "data = data_HA.copy()\n",
    "\n",
    "data[\"delta_velocity\"] = data[\"v_follower\"] - data[\"v_leader\"]\n",
    "data[\"delta_position\"] = data[\"x_leader\"] - data[\"x_follower\"]\n",
    "data = data[[\"case_id\", \"time\", \"delta_position\", \"delta_velocity\", \"v_follower\"]]\n",
    "data = data.sort_values(by=[\"case_id\", \"time\"]).set_index(\"case_id\")\n",
    "\n",
    "# data2 = data2.reset_index(drop=True)\n",
    "features = []\n",
    "labels = []\n",
    "data_prescale = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "data.head()\n",
    "for case_id in tqdm(data.index.unique()):\n",
    "    df = data.loc[case_id][[\"delta_velocity\", \"delta_position\", \"v_follower\"]]\n",
    "    # print(\"df is\")\n",
    "    # print(df.head(3))\n",
    "    X_seqs, y_seqs = create_sequences(df, 30, 10, 1)\n",
    "    X.append(X_seqs)\n",
    "    y.append(y_seqs)\n",
    "    # features.append(\n",
    "    #     (\n",
    "    #         history[[\"time\", \"delta_velocity\", \"delta_position\", \"v_follower\"]],\n",
    "    #         future[[\"time\", \"delta_velocity\", \"delta_position\", \"v_follower\"]],\n",
    "    #     )\n",
    "    # )\n",
    "    # labels.append(\n",
    "    #     (\n",
    "    #         history[[\"time\", \"v_follower\"]],\n",
    "    #         future[[\"time\", \"v_follower\"]],\n",
    "    #     )\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (26394,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/var/www/car-following-project/ai/yiru.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# X_out = np.array(X)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# y_out = np.array(y)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# features = pd.concat(features).reset_index()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Standardize features\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# scaler must be\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m features \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m features\u001b[39m.\u001b[39mto_hdf(\u001b[39m\"\u001b[39m\u001b[39m../ready_data/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHA.h5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/var/www/car-following-project/ai/yiru.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m../ready_data/HA_scaler.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/car-following-project-UTHu64Qq/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/car-following-project-UTHu64Qq/lib/python3.11/site-packages/sklearn/base.py:919\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/car-following-project-UTHu64Qq/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:839\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 839\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/car-following-project-UTHu64Qq/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/car-following-project-UTHu64Qq/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:875\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \n\u001b[1;32m    845\u001b[0m \u001b[39mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    874\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    876\u001b[0m     X,\n\u001b[1;32m    877\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    878\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    879\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    880\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[1;32m    881\u001b[0m )\n\u001b[1;32m    882\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/car-following-project-UTHu64Qq/lib/python3.11/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/car-following-project-UTHu64Qq/lib/python3.11/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    916\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/car-following-project-UTHu64Qq/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (26394,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# X_out = np.array(X)\n",
    "# y_out = np.array(y)\n",
    "# features = pd.concat(features).reset_index()\n",
    "# Standardize features\n",
    "\n",
    "# scaler must be\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(X, y)\n",
    "\n",
    "features.to_hdf(\"../ready_data/\" + \"HA.h5\")\n",
    "\n",
    "with open(\"../ready_data/HA_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# read scaler\n",
    "\n",
    "# with open(\"file/path/scaler.pkl\", \"rb\") as f:\n",
    "#     sc = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car-following-project-UTHu64Qq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
